{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB = True\n",
    "COLAB = False\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = ''\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/')\n",
    "    path = '/content/gdrive/MyDrive/fma/'\n",
    "    sys.path.append('/content/gdrive/MyDrive/fma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "from tqdm import notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        try:\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                'category', categories=SUBSETS, ordered=True)\n",
    "        except (ValueError, TypeError):\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size = 'small'\n",
    "size = 'medium'\n",
    "# size = 'large'\n",
    "os.environ['AUDIO_DIR'] = f'./data/fma_{size}/'\n",
    "tracks = load(f'{path}data/fma_metadata/tracks.csv')\n",
    "features = load(f'{path}data/fma_metadata/features.csv')\n",
    "echonest = load(f'{path}data/fma_metadata/echonest.csv')\n",
    "subset = tracks.index[tracks['set', 'subset'] <= size]\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "features_all = features.loc[subset]\n",
    "tracks = tracks.loc[subset]\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 19922, Validation: 2505, Test: 2573\n",
      "All genres: (151), Top genres (16): ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "validation = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "print(f'Train: {len(train)}, Validation: {len(validation)}, Test: {len(test)}')\n",
    "\n",
    "top_genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "all_genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print(f'All genres: ({len(all_genres)}), Top genres ({len(top_genres)}): {top_genres}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5678a0e82e4546269a07aa2fed424623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hocke\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        encoder = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "    else:\n",
    "        encoder = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = encoder.fit_transform(labels[train])\n",
    "    y_validation = encoder.transform(labels[validation])\n",
    "    y_test = encoder.transform(labels[test])\n",
    "    X_train = features.loc[train, columns].values\n",
    "    X_validation = features.loc[validation, columns].values\n",
    "    X_test = features.loc[test, columns].values\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=RANDOM_SEED)\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_validation)\n",
    "    scaler.transform(X_test)\n",
    "    return y_train, y_validation, y_test, X_train, X_validation, X_test\n",
    "\n",
    "\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "\n",
    "    columns = list(classifiers.keys()).insert(0, 'number of features')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "    for fset_name, fset in notebook.tqdm(feature_sets.items(), desc='features'):\n",
    "        y_train, y_validation, y_test, X_train, X_validation, X_test = pre_process(\n",
    "            tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'number of features'] = X_train.shape[1]\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "    return scores, times\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVC (RBF)': SVC(kernel='rbf', gamma='scale'),\n",
    "    'SVC (Linear)': SVC(kernel='linear'),\n",
    "    'SVC (Polynomial^2)': SVC(kernel='poly', degree=2, gamma='scale'),\n",
    "    'SVC (Polynomial^3)': SVC(kernel='poly', degree=3, gamma='scale'),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000)\n",
    "}\n",
    "\n",
    "feature_sets = {'mfcc': ['mfcc'],\n",
    "                'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "                'all fma features': ['tonnetz', 'zcr', 'chroma_cqt', 'chroma_cens', 'spectral_contrast',\n",
    "                                     'spectral_rolloff', 'spectral_centroid', 'mfcc', 'rmse', 'chroma_stft', 'spectral_bandwidth']}\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c83b97a4bb1d9aa4b5c50cf9b870cc244a5439d22739f63e636556ef3ca71682"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
